{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>rhum</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>vis</th>\n",
       "      <th>clamt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>23</td>\n",
       "      <td>25000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>23</td>\n",
       "      <td>25000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1022.4</td>\n",
       "      <td>22</td>\n",
       "      <td>25000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>22</td>\n",
       "      <td>25000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>23</td>\n",
       "      <td>25000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rain  temp  rhum     msl  wdsp    vis  clamt\n",
       "0   0.0   8.4  75.0  1023.9    23  25000      3\n",
       "1   0.0   8.6  73.0  1023.5    23  25000      6\n",
       "2   0.0   9.0  73.0  1022.4    22  25000      6\n",
       "3   0.0   9.5  73.0  1022.0    22  25000      6\n",
       "4   0.0   9.5  73.0  1022.0    23  25000      6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../532_dublin_airport.csv\", sep=',', usecols=[3,5,10, 11, 13, 19, 21])\n",
    "data = data.dropna(axis=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 720, 6)]          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                4992      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,025\n",
      "Trainable params: 5,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1946\n",
      "Epoch 1: val_loss improved from inf to 0.17756, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 1219s 2s/step - loss: 0.1946 - val_loss: 0.1776\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 2: val_loss did not improve from 0.17756\n",
      "734/734 [==============================] - 1251s 2s/step - loss: 0.1815 - val_loss: 0.1790\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1822\n",
      "Epoch 3: val_loss did not improve from 0.17756\n",
      "734/734 [==============================] - 1257s 2s/step - loss: 0.1822 - val_loss: 0.1799\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1821\n",
      "Epoch 4: val_loss did not improve from 0.17756\n",
      "734/734 [==============================] - 1249s 2s/step - loss: 0.1821 - val_loss: 0.1784\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1803\n",
      "Epoch 5: val_loss improved from 0.17756 to 0.17722, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 1383s 2s/step - loss: 0.1803 - val_loss: 0.1772\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1796\n",
      "Epoch 6: val_loss improved from 0.17722 to 0.17702, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 1559s 2s/step - loss: 0.1796 - val_loss: 0.1770\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1794\n",
      "Epoch 7: val_loss improved from 0.17702 to 0.17682, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 1481s 2s/step - loss: 0.1794 - val_loss: 0.1768\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1798\n",
      "Epoch 8: val_loss did not improve from 0.17682\n",
      "734/734 [==============================] - 972s 1s/step - loss: 0.1798 - val_loss: 0.1773\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 9: val_loss improved from 0.17682 to 0.17680, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 857s 1s/step - loss: 0.1795 - val_loss: 0.1768\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1793\n",
      "Epoch 10: val_loss improved from 0.17680 to 0.17665, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 885s 1s/step - loss: 0.1793 - val_loss: 0.1766\n"
     ]
    }
   ],
   "source": [
    "prediction_1LSTM(data, a=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 336, 6)]          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                4992      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,025\n",
      "Trainable params: 5,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1951\n",
      "Epoch 1: val_loss improved from inf to 0.18122, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 295s 389ms/step - loss: 0.1951 - val_loss: 0.1812\n",
      "Epoch 2/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 2: val_loss improved from 0.18122 to 0.18068, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 641s 856ms/step - loss: 0.1783 - val_loss: 0.1807\n",
      "Epoch 3/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 3: val_loss did not improve from 0.18068\n",
      "736/736 [==============================] - 670s 894ms/step - loss: 0.1781 - val_loss: 0.1808\n",
      "Epoch 4/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 4: val_loss did not improve from 0.18068\n",
      "736/736 [==============================] - 296s 386ms/step - loss: 0.1781 - val_loss: 0.1808\n",
      "Epoch 5/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 5: val_loss did not improve from 0.18068\n",
      "736/736 [==============================] - 290s 388ms/step - loss: 0.1781 - val_loss: 0.1808\n",
      "Epoch 6/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 6: val_loss did not improve from 0.18068\n",
      "736/736 [==============================] - 293s 392ms/step - loss: 0.1780 - val_loss: 0.1808\n",
      "Epoch 7/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 7: val_loss did not improve from 0.18068\n",
      "736/736 [==============================] - 302s 405ms/step - loss: 0.1780 - val_loss: 0.1807\n"
     ]
    }
   ],
   "source": [
    "prediction_1LSTM(data, past=336, a=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 336, 6)]          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 10)                680       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 691\n",
      "Trainable params: 691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1912\n",
      "Epoch 1: val_loss improved from inf to 0.18076, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 126s 159ms/step - loss: 0.1912 - val_loss: 0.1808\n",
      "Epoch 2/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1777\n",
      "Epoch 2: val_loss improved from 0.18076 to 0.18066, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 129s 170ms/step - loss: 0.1777 - val_loss: 0.1807\n",
      "Epoch 3/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1776\n",
      "Epoch 3: val_loss did not improve from 0.18066\n",
      "736/736 [==============================] - 128s 167ms/step - loss: 0.1776 - val_loss: 0.1807\n",
      "Epoch 4/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1776\n",
      "Epoch 4: val_loss did not improve from 0.18066\n",
      "736/736 [==============================] - 128s 168ms/step - loss: 0.1776 - val_loss: 0.1807\n",
      "Epoch 5/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1776\n",
      "Epoch 5: val_loss did not improve from 0.18066\n",
      "736/736 [==============================] - 128s 168ms/step - loss: 0.1776 - val_loss: 0.1807\n",
      "Epoch 6/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1777\n",
      "Epoch 6: val_loss did not improve from 0.18066\n",
      "736/736 [==============================] - 134s 176ms/step - loss: 0.1777 - val_loss: 0.1807\n",
      "Epoch 7/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1776\n",
      "Epoch 7: val_loss did not improve from 0.18066\n",
      "736/736 [==============================] - 135s 174ms/step - loss: 0.1776 - val_loss: 0.1808\n"
     ]
    }
   ],
   "source": [
    "prediction_1LSTM(data, past=336, a=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 336, 6)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                18176     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,241\n",
      "Trainable params: 18,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1900\n",
      "Epoch 1: val_loss improved from inf to 0.18199, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 478s 647ms/step - loss: 0.1900 - val_loss: 0.1820\n",
      "Epoch 2/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1794\n",
      "Epoch 2: val_loss improved from 0.18199 to 0.18141, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 524s 712ms/step - loss: 0.1794 - val_loss: 0.1814\n",
      "Epoch 3/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1793\n",
      "Epoch 3: val_loss did not improve from 0.18141\n",
      "736/736 [==============================] - 555s 755ms/step - loss: 0.1793 - val_loss: 0.1819\n",
      "Epoch 4/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1789\n",
      "Epoch 4: val_loss did not improve from 0.18141\n",
      "736/736 [==============================] - 700s 951ms/step - loss: 0.1789 - val_loss: 0.1814\n",
      "Epoch 5/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1788\n",
      "Epoch 5: val_loss improved from 0.18141 to 0.18122, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 579s 779ms/step - loss: 0.1788 - val_loss: 0.1812\n",
      "Epoch 6/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 6: val_loss improved from 0.18122 to 0.18107, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 603s 812ms/step - loss: 0.1786 - val_loss: 0.1811\n",
      "Epoch 7/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 7: val_loss did not improve from 0.18107\n",
      "736/736 [==============================] - 977s 1s/step - loss: 0.1785 - val_loss: 0.1812\n",
      "Epoch 8/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 8: val_loss improved from 0.18107 to 0.18099, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 859s 1s/step - loss: 0.1785 - val_loss: 0.1810\n",
      "Epoch 9/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 9: val_loss did not improve from 0.18099\n",
      "736/736 [==============================] - 600s 808ms/step - loss: 0.1786 - val_loss: 0.1812\n",
      "Epoch 10/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 10: val_loss did not improve from 0.18099\n",
      "736/736 [==============================] - 694s 936ms/step - loss: 0.1785 - val_loss: 0.1811\n"
     ]
    }
   ],
   "source": [
    "prediction_1LSTM(data, past=336, a=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 336, 6)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                4992      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,025\n",
      "Trainable params: 5,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1860\n",
      "Epoch 1: val_loss improved from inf to 0.18223, saving model to model_checkpoint.h5\n",
      "1471/1471 [==============================] - 220s 148ms/step - loss: 0.1860 - val_loss: 0.1822\n",
      "Epoch 2/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1794\n",
      "Epoch 2: val_loss improved from 0.18223 to 0.18177, saving model to model_checkpoint.h5\n",
      "1471/1471 [==============================] - 242s 165ms/step - loss: 0.1794 - val_loss: 0.1818\n",
      "Epoch 3/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 3: val_loss improved from 0.18177 to 0.18131, saving model to model_checkpoint.h5\n",
      "1471/1471 [==============================] - 239s 162ms/step - loss: 0.1786 - val_loss: 0.1813\n",
      "Epoch 4/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 4: val_loss improved from 0.18131 to 0.18119, saving model to model_checkpoint.h5\n",
      "1471/1471 [==============================] - 225s 153ms/step - loss: 0.1786 - val_loss: 0.1812\n",
      "Epoch 5/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1787\n",
      "Epoch 5: val_loss improved from 0.18119 to 0.18119, saving model to model_checkpoint.h5\n",
      "1471/1471 [==============================] - 228s 155ms/step - loss: 0.1787 - val_loss: 0.1812\n",
      "Epoch 6/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 6: val_loss did not improve from 0.18119\n",
      "1471/1471 [==============================] - 227s 155ms/step - loss: 0.1784 - val_loss: 0.1812\n",
      "Epoch 7/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 7: val_loss improved from 0.18119 to 0.18097, saving model to model_checkpoint.h5\n",
      "1471/1471 [==============================] - 231s 157ms/step - loss: 0.1786 - val_loss: 0.1810\n",
      "Epoch 8/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 8: val_loss did not improve from 0.18097\n",
      "1471/1471 [==============================] - 228s 155ms/step - loss: 0.1785 - val_loss: 0.1812\n",
      "Epoch 9/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1787\n",
      "Epoch 9: val_loss did not improve from 0.18097\n",
      "1471/1471 [==============================] - 226s 154ms/step - loss: 0.1787 - val_loss: 0.1811\n",
      "Epoch 10/10\n",
      "1471/1471 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 10: val_loss did not improve from 0.18097\n",
      "1471/1471 [==============================] - 226s 153ms/step - loss: 0.1784 - val_loss: 0.1811\n"
     ]
    }
   ],
   "source": [
    "prediction_1LSTM(data, past=336, a=32, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 336, 6)]          0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 336, 50)           350       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 336, 20)           1020      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 336, 5)            105       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 336, 1)            6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "735/736 [============================>.] - ETA: 0s - loss: 0.1853\n",
      "Epoch 1: val_loss improved from inf to 0.18843, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 231s 292ms/step - loss: 0.1852 - val_loss: 0.1884\n",
      "Epoch 2/10\n",
      "735/736 [============================>.] - ETA: 0s - loss: 0.1853\n",
      "Epoch 2: val_loss did not improve from 0.18843\n",
      "736/736 [==============================] - 188s 239ms/step - loss: 0.1852 - val_loss: 0.1884\n",
      "Epoch 3/10\n",
      "735/736 [============================>.] - ETA: 0s - loss: 0.1853\n",
      "Epoch 3: val_loss did not improve from 0.18843\n",
      "736/736 [==============================] - 185s 238ms/step - loss: 0.1852 - val_loss: 0.1884\n",
      "Epoch 4/10\n",
      "735/736 [============================>.] - ETA: 0s - loss: 0.1853\n",
      "Epoch 4: val_loss did not improve from 0.18843\n",
      "736/736 [==============================] - 187s 240ms/step - loss: 0.1852 - val_loss: 0.1884\n",
      "Epoch 5/10\n",
      "735/736 [============================>.] - ETA: 0s - loss: 0.1853\n",
      "Epoch 5: val_loss did not improve from 0.18843\n",
      "736/736 [==============================] - 539s 719ms/step - loss: 0.1852 - val_loss: 0.1884\n",
      "Epoch 6/10\n",
      "735/736 [============================>.] - ETA: 0s - loss: 0.1853"
     ]
    }
   ],
   "source": [
    "prediction_DENSE(data, past=336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 336, 6)]          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                4992      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,333\n",
      "Trainable params: 5,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1835\n",
      "Epoch 1: val_loss improved from inf to 0.18289, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 237s 316ms/step - loss: 0.1835 - val_loss: 0.1829\n",
      "Epoch 2/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 2: val_loss improved from 0.18289 to 0.18199, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 244s 332ms/step - loss: 0.1795 - val_loss: 0.1820\n",
      "Epoch 3/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 3: val_loss improved from 0.18199 to 0.18176, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 221s 300ms/step - loss: 0.1795 - val_loss: 0.1818\n",
      "Epoch 4/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1791\n",
      "Epoch 4: val_loss did not improve from 0.18176\n",
      "736/736 [==============================] - 239s 325ms/step - loss: 0.1791 - val_loss: 0.1818\n",
      "Epoch 5/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1791\n",
      "Epoch 5: val_loss did not improve from 0.18176\n",
      "736/736 [==============================] - 229s 311ms/step - loss: 0.1791 - val_loss: 0.1818\n",
      "Epoch 6/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1790\n",
      "Epoch 6: val_loss did not improve from 0.18176\n",
      "736/736 [==============================] - 238s 323ms/step - loss: 0.1790 - val_loss: 0.1818\n",
      "Epoch 7/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1789\n",
      "Epoch 7: val_loss did not improve from 0.18176\n",
      "736/736 [==============================] - 242s 329ms/step - loss: 0.1789 - val_loss: 0.1818\n",
      "Epoch 8/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1789\n",
      "Epoch 8: val_loss improved from 0.18176 to 0.18172, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 243s 331ms/step - loss: 0.1789 - val_loss: 0.1817\n",
      "Epoch 9/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1787\n",
      "Epoch 9: val_loss improved from 0.18172 to 0.18169, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 244s 331ms/step - loss: 0.1787 - val_loss: 0.1817\n",
      "Epoch 10/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1788\n",
      "Epoch 10: val_loss improved from 0.18169 to 0.18165, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 244s 331ms/step - loss: 0.1788 - val_loss: 0.1817\n"
     ]
    }
   ],
   "source": [
    "prediction_1LSTM_2D(data, a=32, b=10, past=336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 336, 6)]          0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 32)                3840      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,873\n",
      "Trainable params: 3,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.2102\n",
      "Epoch 1: val_loss improved from inf to 0.19081, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 238s 321ms/step - loss: 0.2102 - val_loss: 0.1908\n",
      "Epoch 2/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1831\n",
      "Epoch 2: val_loss improved from 0.19081 to 0.18391, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 214s 291ms/step - loss: 0.1831 - val_loss: 0.1839\n",
      "Epoch 3/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1817\n",
      "Epoch 3: val_loss improved from 0.18391 to 0.18268, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 216s 293ms/step - loss: 0.1817 - val_loss: 0.1827\n",
      "Epoch 4/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1807\n",
      "Epoch 4: val_loss did not improve from 0.18268\n",
      "736/736 [==============================] - 210s 286ms/step - loss: 0.1807 - val_loss: 0.1843\n",
      "Epoch 5/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1801\n",
      "Epoch 5: val_loss did not improve from 0.18268\n",
      "736/736 [==============================] - 209s 285ms/step - loss: 0.1801 - val_loss: 0.1837\n",
      "Epoch 6/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 6: val_loss did not improve from 0.18268\n",
      "736/736 [==============================] - 209s 284ms/step - loss: 0.1815 - val_loss: 0.1839\n",
      "Epoch 7/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1806\n",
      "Epoch 7: val_loss improved from 0.18268 to 0.18218, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 237s 321ms/step - loss: 0.1806 - val_loss: 0.1822\n",
      "Epoch 8/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1798\n",
      "Epoch 8: val_loss improved from 0.18218 to 0.18175, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 273s 370ms/step - loss: 0.1798 - val_loss: 0.1817\n",
      "Epoch 9/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1792\n",
      "Epoch 9: val_loss improved from 0.18175 to 0.18107, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 271s 369ms/step - loss: 0.1792 - val_loss: 0.1811\n",
      "Epoch 10/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 10: val_loss did not improve from 0.18107\n",
      "736/736 [==============================] - 264s 358ms/step - loss: 0.1795 - val_loss: 0.1815\n"
     ]
    }
   ],
   "source": [
    "prediction_1GRU(data, a=32, past=336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 336, 6)]          0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 32)                3840      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,181\n",
      "Trainable params: 4,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.2680\n",
      "Epoch 1: val_loss improved from inf to 0.19289, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 255s 343ms/step - loss: 0.2680 - val_loss: 0.1929\n",
      "Epoch 2/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1890\n",
      "Epoch 2: val_loss improved from 0.19289 to 0.18579, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 220s 299ms/step - loss: 0.1890 - val_loss: 0.1858\n",
      "Epoch 3/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1835\n",
      "Epoch 3: val_loss did not improve from 0.18579\n",
      "736/736 [==============================] - 231s 314ms/step - loss: 0.1835 - val_loss: 0.1877\n",
      "Epoch 4/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1835\n",
      "Epoch 4: val_loss improved from 0.18579 to 0.18315, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 213s 290ms/step - loss: 0.1835 - val_loss: 0.1832\n",
      "Epoch 5/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1818\n",
      "Epoch 5: val_loss improved from 0.18315 to 0.18164, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 212s 289ms/step - loss: 0.1818 - val_loss: 0.1816\n",
      "Epoch 6/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1820\n",
      "Epoch 6: val_loss did not improve from 0.18164\n",
      "736/736 [==============================] - 236s 321ms/step - loss: 0.1820 - val_loss: 0.1826\n",
      "Epoch 7/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1826\n",
      "Epoch 7: val_loss did not improve from 0.18164\n",
      "736/736 [==============================] - 215s 292ms/step - loss: 0.1826 - val_loss: 0.1831\n",
      "Epoch 8/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 8: val_loss improved from 0.18164 to 0.18106, saving model to model_checkpoint.h5\n",
      "736/736 [==============================] - 220s 299ms/step - loss: 0.1815 - val_loss: 0.1811\n",
      "Epoch 9/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 9: val_loss did not improve from 0.18106\n",
      "736/736 [==============================] - 219s 297ms/step - loss: 0.1815 - val_loss: 0.1813\n",
      "Epoch 10/10\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1810\n",
      "Epoch 10: val_loss did not improve from 0.18106\n",
      "736/736 [==============================] - 216s 293ms/step - loss: 0.1810 - val_loss: 0.1826\n"
     ]
    }
   ],
   "source": [
    "prediction_1GRU_2D(data, a=32, b=10, past=336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 720, 6)]          0         \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 10)                540       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 551\n",
      "Trainable params: 551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.2885\n",
      "Epoch 1: val_loss improved from inf to 0.18147, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 180s 243ms/step - loss: 0.2885 - val_loss: 0.1815\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 2: val_loss improved from 0.18147 to 0.17896, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 174s 238ms/step - loss: 0.1804 - val_loss: 0.1790\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1797\n",
      "Epoch 3: val_loss improved from 0.17896 to 0.17763, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 176s 240ms/step - loss: 0.1797 - val_loss: 0.1776\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1790\n",
      "Epoch 4: val_loss improved from 0.17763 to 0.17683, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 179s 243ms/step - loss: 0.1790 - val_loss: 0.1768\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1787\n",
      "Epoch 5: val_loss improved from 0.17683 to 0.17637, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 175s 238ms/step - loss: 0.1787 - val_loss: 0.1764\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 6: val_loss improved from 0.17637 to 0.17618, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 177s 241ms/step - loss: 0.1785 - val_loss: 0.1762\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 7: val_loss improved from 0.17618 to 0.17616, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 175s 239ms/step - loss: 0.1785 - val_loss: 0.1762\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 8: val_loss did not improve from 0.17616\n",
      "734/734 [==============================] - 176s 240ms/step - loss: 0.1785 - val_loss: 0.1762\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 9: val_loss did not improve from 0.17616\n",
      "734/734 [==============================] - 179s 244ms/step - loss: 0.1786 - val_loss: 0.1762\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 10: val_loss improved from 0.17616 to 0.17612, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 177s 241ms/step - loss: 0.1784 - val_loss: 0.1761\n"
     ]
    }
   ],
   "source": [
    "prediction_1GRU(data, a=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 720, 6)]          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 10)                680       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 691\n",
      "Trainable params: 691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.2629\n",
      "Epoch 1: val_loss improved from inf to 0.17605, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 182s 245ms/step - loss: 0.2629 - val_loss: 0.1761\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 2: val_loss improved from 0.17605 to 0.17600, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 190s 259ms/step - loss: 0.1780 - val_loss: 0.1760\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1779\n",
      "Epoch 3: val_loss improved from 0.17600 to 0.17599, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 188s 257ms/step - loss: 0.1779 - val_loss: 0.1760\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1779\n",
      "Epoch 4: val_loss did not improve from 0.17599\n",
      "734/734 [==============================] - 194s 264ms/step - loss: 0.1779 - val_loss: 0.1760\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1779\n",
      "Epoch 5: val_loss did not improve from 0.17599\n",
      "734/734 [==============================] - 189s 258ms/step - loss: 0.1779 - val_loss: 0.1760\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 6: val_loss did not improve from 0.17599\n",
      "734/734 [==============================] - 190s 259ms/step - loss: 0.1780 - val_loss: 0.1760\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 7: val_loss did not improve from 0.17599\n",
      "734/734 [==============================] - 195s 266ms/step - loss: 0.1780 - val_loss: 0.1760\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 8: val_loss did not improve from 0.17599\n",
      "734/734 [==============================] - 192s 261ms/step - loss: 0.1780 - val_loss: 0.1760\n"
     ]
    }
   ],
   "source": [
    "prediction_1LSTM(data, a=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 720, 6)]          0         \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 720, 20)           1680      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 10)                1240      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,981\n",
      "Trainable params: 2,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1797\n",
      "Epoch 1: val_loss improved from inf to 0.17628, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 958s 1s/step - loss: 0.1797 - val_loss: 0.1763\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 2: val_loss improved from 0.17628 to 0.17606, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 988s 1s/step - loss: 0.1785 - val_loss: 0.1761\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 3: val_loss improved from 0.17606 to 0.17602, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 1002s 1s/step - loss: 0.1784 - val_loss: 0.1760\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1782\n",
      "Epoch 4: val_loss improved from 0.17602 to 0.17601, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 992s 1s/step - loss: 0.1782 - val_loss: 0.1760\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1782\n",
      "Epoch 5: val_loss improved from 0.17601 to 0.17600, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 986s 1s/step - loss: 0.1782 - val_loss: 0.1760\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1782\n",
      "Epoch 6: val_loss improved from 0.17600 to 0.17599, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 986s 1s/step - loss: 0.1782 - val_loss: 0.1760\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 7: val_loss improved from 0.17599 to 0.17598, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 985s 1s/step - loss: 0.1781 - val_loss: 0.1760\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 8: val_loss did not improve from 0.17598\n",
      "734/734 [==============================] - 966s 1s/step - loss: 0.1781 - val_loss: 0.1760\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 9: val_loss did not improve from 0.17598\n",
      "734/734 [==============================] - 973s 1s/step - loss: 0.1780 - val_loss: 0.1760\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 10: val_loss did not improve from 0.17598\n",
      "734/734 [==============================] - 972s 1s/step - loss: 0.1780 - val_loss: 0.1760\n"
     ]
    }
   ],
   "source": [
    "prediction_1GRU_1LSTM_1DENSE(data, a=20, b=10, c=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the best model, according to validation loss, training loss and number of parameters, that is the one with 1 Long Short Term Memory (LSTM) layer with dimension 10 for the output.\n",
    "We run it again in order to create plots of loss and to make prediction on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 720, 6)]          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 10)                680       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 691\n",
      "Trainable params: 691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1832\n",
      "Epoch 1: val_loss improved from inf to 0.17658, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 290s 386ms/step - loss: 0.1832 - val_loss: 0.1766\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1788\n",
      "Epoch 2: val_loss improved from 0.17658 to 0.17631, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 373s 500ms/step - loss: 0.1788 - val_loss: 0.1763\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 3: val_loss improved from 0.17631 to 0.17628, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 427s 569ms/step - loss: 0.1784 - val_loss: 0.1763\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 4: val_loss improved from 0.17628 to 0.17617, saving model to model_checkpoint.h5\n",
      "734/734 [==============================] - 399s 530ms/step - loss: 0.1786 - val_loss: 0.1762\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 5: val_loss did not improve from 0.17617\n",
      "734/734 [==============================] - 429s 584ms/step - loss: 0.1783 - val_loss: 0.1762\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 6: val_loss did not improve from 0.17617\n",
      "734/734 [==============================] - 358s 488ms/step - loss: 0.1783 - val_loss: 0.1763\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 7: val_loss did not improve from 0.17617\n",
      "734/734 [==============================] - 349s 475ms/step - loss: 0.1784 - val_loss: 0.1763\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 8: val_loss did not improve from 0.17617\n",
      "734/734 [==============================] - 319s 434ms/step - loss: 0.1784 - val_loss: 0.1763\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 9: val_loss did not improve from 0.17617\n",
      "734/734 [==============================] - 299s 408ms/step - loss: 0.1785 - val_loss: 0.1763\n"
     ]
    }
   ],
   "source": [
    "a=10\n",
    "split_fraction=0.715\n",
    "step=1\n",
    "past=720\n",
    "future=24\n",
    "learning_rate=0.001\n",
    "batch_size=256\n",
    "epochs=10\n",
    "train_split = int(split_fraction * int(data.shape[0]))\n",
    "train_data = data.loc[0 : train_split - 1]\n",
    "val_data = data.loc[train_split:]\n",
    "start = past + future #start of y lablels\n",
    "end = start + train_split #end of y labels\n",
    "x_end = len(val_data) - past - future#index of the last x to consider for the validation set\n",
    "\n",
    "x_train = train_data.drop('rain', axis=1)    \n",
    "y_train = data.iloc[start:end,0]\n",
    "\n",
    "x_val = val_data.drop('rain', axis=1).iloc[:x_end]\n",
    "y_val = val_data.iloc[start:,0]\n",
    "\n",
    "sequence_length = int(past/step)\n",
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "x_train,#x\n",
    "y_train,#y\n",
    "sequence_length=sequence_length,#number of x needed to predict the y\n",
    "sampling_rate=step,#how many timestamp to skip\n",
    "batch_size=batch_size,#number of timeseries in each batch\n",
    ")\n",
    "\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "        inputs, targets = batch\n",
    "        \n",
    "#NN\n",
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out = keras.layers.LSTM(a)(inputs)#long short term memory layer\n",
    "outputs = keras.layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")#Adam for gradient descent\n",
    "print(model.summary())\n",
    "   \n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint( #allows to save model parameters for each epoch such that the best \n",
    "        #can be found (no risk of losing efficiency in successive epochs)\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=\"model_checkpoint.h5\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss over iterations for TYPE model')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot Loss\n",
    "fig, ax = plt.subplots(figsize = (12, 4))\n",
    "ax.plot(range(len(history.history[\"loss\"])), (history.history[\"loss\"]),'r-', label = \"Train Loss\")\n",
    "ax.plot(range(len(history.history[\"val_loss\"])), (history.history[\"val_loss\"]),'b-', label=\"Validation Loss\")\n",
    "plt.ylim([0.15, 0.2])\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations for TYPE model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset_val.take(1):\n",
    "        inputs, targets = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(list(targets))\n",
    "plt.plot(list(y_hat))\n",
    "plt.title(\"True values Vs predicted\")\n",
    "plt.ylabel(\"Amount of rain\")\n",
    "plt.legend((\"True\",\"Predicted\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
